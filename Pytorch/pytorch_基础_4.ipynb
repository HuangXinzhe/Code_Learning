{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data\n",
    "Y = boston.target\n",
    "print(np.shape(X))\n",
    "print(np.shape(Y))\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "X = std.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegressionModel(\n",
      "  (linear): Linear(in_features=13, out_features=100, bias=True)\n",
      "  (linear2): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## 定义模型\n",
    "class RegressionModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(RegressionModel,self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 100)\n",
    "        self.linear2 = nn.Linear(100, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = f.relu(x)\n",
    "        out = self.linear2(x)\n",
    "        return out\n",
    "# 模型实例化\n",
    "input_dim = 13\n",
    "output_dim = 1\n",
    "model = RegressionModel(input_dim, output_dim)\n",
    "print(model)\n",
    "## 定义损失函数和优化器\n",
    "learning_rate = 0.0001\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(torch.nn.MSELoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 601.3571166992188, test_loss: 610.4064331054688\n",
      "epoch: 100, train_loss: 585.7545166015625, test_loss: 594.1322631835938\n",
      "epoch: 200, train_loss: 569.34912109375, test_loss: 576.8253784179688\n",
      "epoch: 300, train_loss: 550.6537475585938, test_loss: 556.7950439453125\n",
      "epoch: 400, train_loss: 528.9808349609375, test_loss: 533.206787109375\n",
      "epoch: 500, train_loss: 503.9185485839844, test_loss: 505.72698974609375\n",
      "epoch: 600, train_loss: 475.37841796875, test_loss: 474.3448486328125\n",
      "epoch: 700, train_loss: 443.6724548339844, test_loss: 439.4716491699219\n",
      "epoch: 800, train_loss: 409.5365905761719, test_loss: 401.9920959472656\n",
      "epoch: 900, train_loss: 373.9753723144531, test_loss: 363.0768737792969\n",
      "epoch: 1000, train_loss: 338.03106689453125, test_loss: 324.1041564941406\n",
      "epoch: 1100, train_loss: 302.83319091796875, test_loss: 286.4101867675781\n",
      "epoch: 1200, train_loss: 269.25762939453125, test_loss: 250.92088317871094\n",
      "epoch: 1300, train_loss: 237.95741271972656, test_loss: 218.37945556640625\n",
      "epoch: 1400, train_loss: 209.3744659423828, test_loss: 189.2842254638672\n",
      "epoch: 1500, train_loss: 183.78343200683594, test_loss: 163.88070678710938\n",
      "epoch: 1600, train_loss: 161.18289184570312, test_loss: 142.0507049560547\n",
      "epoch: 1700, train_loss: 141.40478515625, test_loss: 123.4784927368164\n",
      "epoch: 1800, train_loss: 124.20604705810547, test_loss: 107.74394989013672\n",
      "epoch: 1900, train_loss: 109.31739044189453, test_loss: 94.4249038696289\n",
      "epoch: 2000, train_loss: 96.43966674804688, test_loss: 83.12040710449219\n",
      "epoch: 2100, train_loss: 85.34784698486328, test_loss: 73.50599670410156\n",
      "epoch: 2200, train_loss: 75.8349380493164, test_loss: 65.32342529296875\n",
      "epoch: 2300, train_loss: 67.69799041748047, test_loss: 58.34239196777344\n",
      "epoch: 2400, train_loss: 60.77301788330078, test_loss: 52.395362854003906\n",
      "epoch: 2500, train_loss: 54.90781021118164, test_loss: 47.31890869140625\n",
      "epoch: 2600, train_loss: 49.97140884399414, test_loss: 43.000946044921875\n",
      "epoch: 2700, train_loss: 45.848506927490234, test_loss: 39.332767486572266\n",
      "epoch: 2800, train_loss: 42.42457580566406, test_loss: 36.21938705444336\n",
      "epoch: 2900, train_loss: 39.5855712890625, test_loss: 33.57891845703125\n",
      "epoch: 3000, train_loss: 37.244598388671875, test_loss: 31.344263076782227\n",
      "epoch: 3100, train_loss: 35.31633758544922, test_loss: 29.45088005065918\n",
      "epoch: 3200, train_loss: 33.72111129760742, test_loss: 27.838191986083984\n",
      "epoch: 3300, train_loss: 32.384178161621094, test_loss: 26.455581665039062\n",
      "epoch: 3400, train_loss: 31.242877960205078, test_loss: 25.248939514160156\n",
      "epoch: 3500, train_loss: 30.258237838745117, test_loss: 24.188365936279297\n",
      "epoch: 3600, train_loss: 29.393936157226562, test_loss: 23.250473022460938\n",
      "epoch: 3700, train_loss: 28.609508514404297, test_loss: 22.395076751708984\n",
      "epoch: 3800, train_loss: 27.88456916809082, test_loss: 21.6054744720459\n",
      "epoch: 3900, train_loss: 27.205732345581055, test_loss: 20.86868667602539\n",
      "epoch: 4000, train_loss: 26.55976104736328, test_loss: 20.172224044799805\n",
      "epoch: 4100, train_loss: 25.941381454467773, test_loss: 19.508045196533203\n",
      "epoch: 4200, train_loss: 25.339176177978516, test_loss: 18.86614418029785\n",
      "epoch: 4300, train_loss: 24.747041702270508, test_loss: 18.251636505126953\n",
      "epoch: 4400, train_loss: 24.16530990600586, test_loss: 17.667253494262695\n",
      "epoch: 4500, train_loss: 23.59309196472168, test_loss: 17.100563049316406\n",
      "epoch: 4600, train_loss: 23.03011131286621, test_loss: 16.5515079498291\n",
      "epoch: 4700, train_loss: 22.474348068237305, test_loss: 16.012924194335938\n",
      "epoch: 4800, train_loss: 21.923206329345703, test_loss: 15.48786449432373\n",
      "epoch: 4900, train_loss: 21.38118553161621, test_loss: 14.983146667480469\n",
      "epoch: 5000, train_loss: 20.846405029296875, test_loss: 14.49647331237793\n",
      "epoch: 5100, train_loss: 20.3173770904541, test_loss: 14.022790908813477\n",
      "epoch: 5200, train_loss: 19.79631233215332, test_loss: 13.562599182128906\n",
      "epoch: 5300, train_loss: 19.281347274780273, test_loss: 13.115212440490723\n",
      "epoch: 5400, train_loss: 18.775957107543945, test_loss: 12.689167976379395\n",
      "epoch: 5500, train_loss: 18.2822208404541, test_loss: 12.28656005859375\n",
      "epoch: 5600, train_loss: 17.80060386657715, test_loss: 11.893497467041016\n",
      "epoch: 5700, train_loss: 17.332477569580078, test_loss: 11.51975154876709\n",
      "epoch: 5800, train_loss: 16.877023696899414, test_loss: 11.162973403930664\n",
      "epoch: 5900, train_loss: 16.43492317199707, test_loss: 10.822379112243652\n",
      "epoch: 6000, train_loss: 16.012704849243164, test_loss: 10.506572723388672\n",
      "epoch: 6100, train_loss: 15.6135835647583, test_loss: 10.218036651611328\n",
      "epoch: 6200, train_loss: 15.228569030761719, test_loss: 9.951066970825195\n",
      "epoch: 6300, train_loss: 14.858302116394043, test_loss: 9.699943542480469\n",
      "epoch: 6400, train_loss: 14.50432300567627, test_loss: 9.466261863708496\n",
      "epoch: 6500, train_loss: 14.167168617248535, test_loss: 9.244824409484863\n",
      "epoch: 6600, train_loss: 13.847199440002441, test_loss: 9.035640716552734\n",
      "epoch: 6700, train_loss: 13.543251991271973, test_loss: 8.842981338500977\n",
      "epoch: 6800, train_loss: 13.253052711486816, test_loss: 8.665645599365234\n",
      "epoch: 6900, train_loss: 12.975770950317383, test_loss: 8.505193710327148\n",
      "epoch: 7000, train_loss: 12.709816932678223, test_loss: 8.35940933227539\n",
      "epoch: 7100, train_loss: 12.463574409484863, test_loss: 8.236629486083984\n",
      "epoch: 7200, train_loss: 12.228049278259277, test_loss: 8.132002830505371\n",
      "epoch: 7300, train_loss: 12.0031156539917, test_loss: 8.03947925567627\n",
      "epoch: 7400, train_loss: 11.787186622619629, test_loss: 7.95844841003418\n",
      "epoch: 7500, train_loss: 11.578875541687012, test_loss: 7.885096549987793\n",
      "epoch: 7600, train_loss: 11.379947662353516, test_loss: 7.826353549957275\n",
      "epoch: 7700, train_loss: 11.193835258483887, test_loss: 7.772747993469238\n",
      "epoch: 7800, train_loss: 11.019378662109375, test_loss: 7.7332763671875\n",
      "epoch: 7900, train_loss: 10.854771614074707, test_loss: 7.700973033905029\n",
      "epoch: 8000, train_loss: 10.690673828125, test_loss: 7.671741962432861\n",
      "epoch: 8100, train_loss: 10.532474517822266, test_loss: 7.636117935180664\n",
      "epoch: 8200, train_loss: 10.379508018493652, test_loss: 7.606712341308594\n",
      "epoch: 8300, train_loss: 10.234701156616211, test_loss: 7.576345443725586\n",
      "epoch: 8400, train_loss: 10.09439754486084, test_loss: 7.547707557678223\n",
      "epoch: 8500, train_loss: 9.958148002624512, test_loss: 7.527310371398926\n",
      "epoch: 8600, train_loss: 9.825721740722656, test_loss: 7.512643814086914\n",
      "epoch: 8700, train_loss: 9.699584007263184, test_loss: 7.494820594787598\n",
      "epoch: 8800, train_loss: 9.577397346496582, test_loss: 7.471933364868164\n",
      "epoch: 8900, train_loss: 9.45752239227295, test_loss: 7.448918342590332\n",
      "epoch: 9000, train_loss: 9.3417387008667, test_loss: 7.422750949859619\n",
      "epoch: 9100, train_loss: 9.229936599731445, test_loss: 7.39285945892334\n",
      "epoch: 9200, train_loss: 9.120911598205566, test_loss: 7.366969108581543\n",
      "epoch: 9300, train_loss: 9.013474464416504, test_loss: 7.346692085266113\n",
      "epoch: 9400, train_loss: 8.908596992492676, test_loss: 7.329519748687744\n",
      "epoch: 9500, train_loss: 8.808488845825195, test_loss: 7.309206962585449\n",
      "epoch: 9600, train_loss: 8.712032318115234, test_loss: 7.284954071044922\n",
      "epoch: 9700, train_loss: 8.617391586303711, test_loss: 7.261790752410889\n",
      "epoch: 9800, train_loss: 8.523194313049316, test_loss: 7.244495868682861\n",
      "epoch: 9900, train_loss: 8.429342269897461, test_loss: 7.218879222869873\n",
      "epoch: 10000, train_loss: 8.338708877563477, test_loss: 7.195518493652344\n",
      "epoch: 10100, train_loss: 8.249863624572754, test_loss: 7.174602508544922\n",
      "epoch: 10200, train_loss: 8.165566444396973, test_loss: 7.157757759094238\n",
      "epoch: 10300, train_loss: 8.08531379699707, test_loss: 7.142922878265381\n",
      "epoch: 10400, train_loss: 8.007525444030762, test_loss: 7.124565601348877\n",
      "epoch: 10500, train_loss: 7.931746959686279, test_loss: 7.103788375854492\n",
      "epoch: 10600, train_loss: 7.860135078430176, test_loss: 7.088681221008301\n",
      "epoch: 10700, train_loss: 7.789555549621582, test_loss: 7.068775177001953\n",
      "epoch: 10800, train_loss: 7.7189106941223145, test_loss: 7.049776077270508\n",
      "epoch: 10900, train_loss: 7.647155284881592, test_loss: 7.032273769378662\n",
      "epoch: 11000, train_loss: 7.576473236083984, test_loss: 7.014533996582031\n",
      "epoch: 11100, train_loss: 7.506766319274902, test_loss: 6.991013526916504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11200, train_loss: 7.439758777618408, test_loss: 6.970978260040283\n",
      "epoch: 11300, train_loss: 7.3730082511901855, test_loss: 6.95139217376709\n",
      "程序结束时的测试数据的最小loss:6.940184116363525,当前模型测试数据的loss:6.940199851989746\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#数据转为tensor类型\n",
    "# inputs = torch.as_tensor(torch.from_numpy(X_train),dtype=torch.float32)\n",
    "# labels = torch.as_tensor(torch.from_numpy(Y_train),dtype=torch.float32)\n",
    "inputs = torch.tensor(X_train,dtype=torch.float32)\n",
    "labels = torch.tensor(Y_train,dtype=torch.float32)\n",
    "\n",
    "\n",
    "#测试集进行测试\n",
    "x_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(Y_test, dtype = torch.float32)\n",
    "\n",
    "epochs = 20000\n",
    "test_min_loss = 1000000\n",
    "all_train_loss = []\n",
    "all_test_loss = []\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    \n",
    "    #前向传播\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    #计算loss\n",
    "    \n",
    "    loss = criterion(outputs, labels.view(-1,1))\n",
    "    all_train_loss.append(loss.item())\n",
    "    #测试集#在backward之前计算测试数据的loss\n",
    "    pred = model.forward(x_test)\n",
    "    test_loss = criterion(pred, y_test.view(-1,1))\n",
    "    all_test_loss.append(test_loss.item())\n",
    "\n",
    "    if test_min_loss > test_loss.item():\n",
    "        test_min_loss = test_loss.item()\n",
    "    else:\n",
    "        print(f'程序结束时的测试数据的最小loss:{test_min_loss},当前模型测试数据的loss:{test_loss.item()}')\n",
    "        break\n",
    "    if epoch % 100 == 0:\n",
    "#             print('epoch {}, train_loss {},test_loss {}'.format(epoch, loss.item(),loss_test.item()))\n",
    "        print(f'epoch: {epoch}, train_loss: {loss.item()}, test_loss: {test_loss.item()}')\n",
    "    #梯度清零\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    #反向传播\n",
    "    loss.backward()\n",
    "\n",
    "    #更新参数\n",
    "    optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[18.3646]], grad_fn=<AddmmBackward0>)\n",
      "19.9\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.tensor(X_test[5],dtype=torch.float32).view(1,-1)\n",
    "print(model(input_))\n",
    "print(Y_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.tensor(X_test,dtype=torch.float32)\n",
    "predicts = model(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts.numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9228142549907157"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(predicts.detach().numpy(),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19a56eda288>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(len(all_train_loss[2000:])), all_train_loss[2000:], color='red',label='train_loss')\n",
    "plt.plot(np.arange(len(all_test_loss[2000:])), all_test_loss[2000:], color='blue',label='test_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model, 'model/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值：44.85979080200195,真实值：43.8\n"
     ]
    }
   ],
   "source": [
    "#加载模型\n",
    "net = torch.load(\"model/model.pkl\")\n",
    "\n",
    "x_data = torch.tensor(X_test[1], dtype=torch.float32)\n",
    "\n",
    "pred = net.forward(x_data.view(1,-1))\n",
    "\n",
    "print('预测值：{},真实值：{}'.format(pred.item(),Y_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch使用gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n",
      "(404, 13)\n",
      "(102, 13)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch.nn.functional as f\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "Y = boston.target\n",
    "print(np.shape(X))\n",
    "print(np.shape(Y))\n",
    "std = StandardScaler()\n",
    "X = std.fit_transform(X)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=66)\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegressionModel(\n",
      "  (linear): Linear(in_features=13, out_features=100, bias=True)\n",
      "  (linear2): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## 定义模型\n",
    "class RegressionModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(RegressionModel,self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 100)\n",
    "        self.linear2 = nn.Linear(100, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = f.relu(x)\n",
    "        out = self.linear2(x)\n",
    "        return out\n",
    "# 模型实例化\n",
    "input_dim = 13\n",
    "output_dim = 1\n",
    "model = RegressionModel(input_dim, output_dim)\n",
    "print(model)\n",
    "## 定义损失函数和优化器\n",
    "learning_rate = 0.0001\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 和cpu的不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionModel(\n",
       "  (linear): Linear(in_features=13, out_features=100, bias=True)\n",
       "  (linear2): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)#把我们的模型搬到我们的gpu上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(X_train,dtype=torch.float32)\n",
    "labels = torch.tensor(Y_train,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试集进行测试\n",
    "x_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(Y_test, dtype = torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A custom Dataset class must implement three functions: __init__, __len__, and __getitem__.\n",
    "### The __init__ function is run once when instantiating the Dataset object.\n",
    "### The __len__ function returns the number of samples in our dataset.\n",
    "### The __getitem__ function loads and returns a sample from the dataset at the given index idx.\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#自定义dataset\n",
    "class myDataset(Dataset):\n",
    "    #初始化，定义数据内容和标签\n",
    "    def __init__(self, Data, Label):\n",
    "        self.Data = Data\n",
    "        self.Label = Label\n",
    "    #返回数据集大小\n",
    "    def __len__(self):\n",
    "        return len(self.Data)\n",
    "    #得到数据内容和标签\n",
    "    def __getitem__(self, index):\n",
    "        data = torch.Tensor(self.Data[index])\n",
    "        \n",
    "        label = torch.Tensor(self.Label[index])\n",
    "#         label = self.Label[index]\n",
    "\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([404])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([404, 13])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3725, -0.4877, -0.7203,  ..., -0.4880,  0.1689, -0.8821],\n",
       "        [-0.4047,  0.0488, -0.7393,  ...,  0.2055,  0.4411,  0.0612],\n",
       "        [-0.3910, -0.4877, -0.6167,  ..., -0.2569,  0.4411,  2.5451],\n",
       "        ...,\n",
       "        [-0.4037, -0.4877, -0.1644,  ..., -0.3031,  0.3818,  0.1341],\n",
       "        [-0.3835, -0.4877, -0.1805,  ..., -0.0257,  0.3731,  0.7958],\n",
       "        [-0.2748, -0.4877, -0.4373,  ...,  1.1765,  0.2181,  1.1728]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = myDataset(inputs,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.myDataset at 0x19a543e8208>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dataset in module torch.utils.data.dataset:\n",
      "\n",
      "class Dataset(typing.Generic)\n",
      " |  Dataset(*args, **kwds)\n",
      " |  \n",
      " |  An abstract class representing a :class:`Dataset`.\n",
      " |  \n",
      " |  All datasets that represent a map from keys to data samples should subclass\n",
      " |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      " |  data sample for a given key. Subclasses could also optionally overwrite\n",
      " |  :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      " |  :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      " |  of :class:`~torch.utils.data.DataLoader`.\n",
      " |  \n",
      " |  .. note::\n",
      " |    :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
      " |    sampler that yields integral indices.  To make it work with a map-style\n",
      " |    dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  __getattr__(self, attribute_name)\n",
      " |  \n",
      " |  __getitem__(self, index) -> +T_co\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  register_datapipe_as_function(function_name, cls_to_register, enable_df_api_tracing=False) from builtins.type\n",
      " |  \n",
      " |  register_function(function_name, function) from builtins.type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'functions': typing.Dict[str, typing.Callable]}\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  __parameters__ = (+T_co,)\n",
      " |  \n",
      " |  functions = {'concat': functools.partial(<function Dataset.register_da...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwds)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.4047,  0.0488, -0.7393, -0.2726, -1.2586, -0.9839, -1.1299,  1.2849,\n",
       "         -0.6380, -0.3756,  0.2055,  0.4411,  0.0612]),\n",
       " tensor(17.4000))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建DataLoader迭代器\n",
    "# The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to\n",
    "# pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to\n",
    "# speed up data retrieval.\n",
    "# DataLoader is an iterable that abstracts this complexity for us in an easy API.\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset,batch_size= 404, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4102,  0.0488, -0.4767,  ..., -1.5052,  0.4268, -0.0313],\n",
      "        [ 0.2127, -0.4877,  1.0160,  ...,  0.8066, -0.0152,  0.7117],\n",
      "        [-0.3577,  0.3707, -1.0457,  ..., -2.5224,  0.3961, -0.4294],\n",
      "        ...,\n",
      "        [-0.4046, -0.4877, -0.0798,  ...,  0.0668,  0.4411, -0.2499],\n",
      "        [ 1.9903, -0.4877,  1.0160,  ...,  0.8066,  0.1485,  1.4980],\n",
      "        [ 0.4553, -0.4877,  1.0160,  ...,  0.8066, -0.5752,  0.9331]])\n",
      "tensor([22.9000, 15.2000, 33.8000, 21.9000, 23.7000, 19.6000, 31.2000, 13.8000,\n",
      "        15.4000, 19.4000, 22.3000,  5.0000, 15.2000,  8.4000, 17.2000, 19.9000,\n",
      "        31.5000, 14.1000,  5.0000, 37.6000, 20.1000, 22.5000, 33.2000, 12.1000,\n",
      "        37.3000, 23.3000, 17.2000, 12.7000, 23.3000, 24.4000, 23.1000, 20.0000,\n",
      "        28.2000, 43.1000, 13.5000, 21.6000, 20.3000, 22.3000, 24.4000, 31.7000,\n",
      "        24.2000, 30.1000, 11.9000,  7.2000, 29.9000,  8.7000, 18.8000, 28.1000,\n",
      "        18.6000, 22.2000,  7.2000, 14.5000, 24.7000, 21.8000, 18.5000, 26.6000,\n",
      "        16.1000, 22.9000, 27.9000, 30.5000, 10.2000, 14.3000, 15.4000, 19.4000,\n",
      "        21.2000, 23.8000, 28.0000, 19.8000, 17.8000, 14.4000, 36.5000, 24.6000,\n",
      "        21.2000, 23.8000, 27.1000, 12.7000, 32.0000, 32.4000, 33.1000, 13.1000,\n",
      "        17.3000, 18.9000, 21.7000, 14.6000, 20.7000, 18.0000, 16.0000, 41.3000,\n",
      "        19.6000, 15.0000, 22.2000, 18.6000, 18.1000, 20.8000, 50.0000, 17.1000,\n",
      "        50.0000, 16.7000, 21.7000, 39.8000, 50.0000, 17.9000, 34.9000, 18.7000,\n",
      "        21.7000, 12.0000, 13.3000, 21.0000, 20.0000,  8.3000, 19.1000, 20.5000,\n",
      "        20.7000, 16.5000, 13.4000, 21.4000, 35.4000, 50.0000, 14.3000, 34.7000,\n",
      "        14.5000, 20.4000, 22.2000, 23.0000, 23.5000, 18.5000, 19.3000, 22.8000,\n",
      "        22.0000, 27.0000, 37.9000, 24.8000, 10.9000, 19.9000, 20.8000, 13.1000,\n",
      "        11.8000, 25.0000, 27.9000, 13.9000, 23.8000, 31.1000, 22.7000, 14.2000,\n",
      "        12.3000, 20.2000, 16.2000, 31.6000, 24.5000,  8.4000, 24.5000, 18.9000,\n",
      "        14.1000, 13.2000, 24.5000, 14.5000, 29.4000, 28.7000, 50.0000, 23.4000,\n",
      "        22.8000, 19.2000, 27.5000, 22.2000, 43.5000, 20.6000, 36.2000, 22.6000,\n",
      "        17.7000, 20.6000, 16.5000, 14.1000, 36.0000, 42.8000, 15.3000, 17.4000,\n",
      "        28.7000, 29.1000, 23.2000,  9.6000, 24.7000, 20.6000, 13.6000, 34.9000,\n",
      "        35.2000, 34.6000, 17.8000, 17.8000, 22.6000, 23.9000, 19.3000, 42.3000,\n",
      "         8.1000, 26.2000, 48.5000, 11.7000, 22.0000, 19.5000, 19.5000, 22.6000,\n",
      "        13.4000, 23.3000, 19.5000, 30.1000, 16.8000, 10.4000, 25.0000, 27.5000,\n",
      "        17.8000,  7.2000, 23.8000, 11.3000, 18.2000, 50.0000, 23.1000, 20.1000,\n",
      "        20.0000, 28.6000, 25.0000, 19.1000, 12.6000, 23.0000, 25.0000, 31.6000,\n",
      "        46.7000, 19.3000, 17.6000, 19.7000, 33.3000, 19.4000, 21.9000,  8.5000,\n",
      "        10.2000, 10.8000, 29.0000, 19.3000, 22.5000, 13.8000, 24.4000, 17.1000,\n",
      "        23.4000, 23.6000, 19.1000, 19.4000, 23.1000, 16.7000, 21.5000, 26.4000,\n",
      "        50.0000, 30.7000, 20.4000, 26.6000, 12.5000, 10.2000, 48.3000, 22.6000,\n",
      "        19.6000, 18.7000, 20.8000, 24.8000, 36.4000, 11.8000, 25.3000, 23.1000,\n",
      "        44.0000, 20.1000, 15.7000, 23.1000, 25.0000, 26.6000, 21.4000, 16.2000,\n",
      "        24.8000, 50.0000, 10.9000, 50.0000, 20.1000, 20.6000, 21.7000, 22.0000,\n",
      "        13.4000, 16.4000, 29.8000, 14.8000, 31.5000, 28.4000, 33.2000,  9.5000,\n",
      "        13.3000, 20.6000, 28.5000, 19.6000, 25.0000, 21.6000, 20.0000, 20.6000,\n",
      "        22.7000, 23.3000, 23.0000, 29.8000, 19.7000,  9.7000, 19.0000, 19.2000,\n",
      "        20.3000, 23.2000, 18.8000, 48.8000,  7.0000, 27.1000, 13.8000, 36.2000,\n",
      "        21.7000, 19.4000, 23.7000, 33.4000, 24.3000, 14.0000, 22.2000,  5.6000,\n",
      "        35.4000, 32.5000, 23.2000, 25.1000, 21.9000, 15.1000, 23.0000, 20.0000,\n",
      "        20.5000, 15.0000, 50.0000, 13.8000, 17.0000, 18.4000, 18.7000, 13.1000,\n",
      "        50.0000, 44.8000, 15.2000, 10.4000, 19.6000, 15.6000, 23.9000, 24.6000,\n",
      "        23.6000, 21.7000, 19.1000, 29.0000, 26.4000, 17.8000,  7.5000, 18.4000,\n",
      "        25.0000, 14.6000, 23.9000, 23.1000, 17.2000, 24.3000, 24.0000,  8.8000,\n",
      "        18.2000, 34.9000, 50.0000, 22.0000, 23.9000, 33.4000, 16.8000, 26.7000,\n",
      "        13.4000, 14.4000, 11.7000, 23.1000, 13.6000, 27.5000, 33.1000, 50.0000,\n",
      "         6.3000, 13.9000, 20.3000, 22.0000, 17.1000, 17.4000, 21.2000, 11.5000,\n",
      "        15.6000, 22.1000, 29.6000, 22.5000, 30.8000, 36.1000, 21.2000,  7.0000,\n",
      "        24.3000, 29.6000, 22.8000, 20.3000, 19.8000, 21.4000, 19.3000, 22.9000,\n",
      "        27.5000, 22.6000, 11.9000, 13.0000])\n"
     ]
    }
   ],
   "source": [
    "for i,data in dataloader:\n",
    "    print(i)\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 590.0119018554688, test_loss: 598.526611328125\n",
      "epoch: 100, train_loss: 572.8847045898438, test_loss: 581.20703125\n",
      "epoch: 200, train_loss: 554.7254638671875, test_loss: 562.5958862304688\n",
      "epoch: 300, train_loss: 534.3814697265625, test_loss: 541.3439331054688\n",
      "epoch: 400, train_loss: 511.1004333496094, test_loss: 516.6636352539062\n",
      "epoch: 500, train_loss: 484.68017578125, test_loss: 488.28509521484375\n",
      "epoch: 600, train_loss: 455.42742919921875, test_loss: 456.72467041015625\n",
      "epoch: 700, train_loss: 423.954833984375, test_loss: 422.704833984375\n",
      "epoch: 800, train_loss: 390.8010559082031, test_loss: 386.9188232421875\n",
      "epoch: 900, train_loss: 356.8375244140625, test_loss: 350.3215637207031\n",
      "epoch: 1000, train_loss: 322.8125, test_loss: 313.7041320800781\n",
      "epoch: 1100, train_loss: 289.3156433105469, test_loss: 277.7528076171875\n",
      "epoch: 1200, train_loss: 256.9112854003906, test_loss: 243.16934204101562\n",
      "epoch: 1300, train_loss: 226.19161987304688, test_loss: 210.67051696777344\n",
      "epoch: 1400, train_loss: 197.80294799804688, test_loss: 181.00933837890625\n",
      "epoch: 1500, train_loss: 172.18716430664062, test_loss: 154.67562866210938\n",
      "epoch: 1600, train_loss: 149.60507202148438, test_loss: 131.97499084472656\n",
      "epoch: 1700, train_loss: 130.06410217285156, test_loss: 112.85162353515625\n",
      "epoch: 1800, train_loss: 113.3692626953125, test_loss: 96.9755859375\n",
      "epoch: 1900, train_loss: 99.21915435791016, test_loss: 83.86173248291016\n",
      "epoch: 2000, train_loss: 87.27397155761719, test_loss: 73.0488052368164\n",
      "epoch: 2100, train_loss: 77.2026138305664, test_loss: 64.09724426269531\n",
      "epoch: 2200, train_loss: 68.70744323730469, test_loss: 56.65870666503906\n",
      "epoch: 2300, train_loss: 61.55105209350586, test_loss: 50.446773529052734\n",
      "epoch: 2400, train_loss: 55.54042434692383, test_loss: 45.2508544921875\n",
      "epoch: 2500, train_loss: 50.496768951416016, test_loss: 40.90122604370117\n",
      "epoch: 2600, train_loss: 46.27849197387695, test_loss: 37.25764083862305\n",
      "epoch: 2700, train_loss: 42.763797760009766, test_loss: 34.20500564575195\n",
      "epoch: 2800, train_loss: 39.8353157043457, test_loss: 31.646533966064453\n",
      "epoch: 2900, train_loss: 37.40406036376953, test_loss: 29.502012252807617\n",
      "epoch: 3000, train_loss: 35.38935470581055, test_loss: 27.699148178100586\n",
      "epoch: 3100, train_loss: 33.72001647949219, test_loss: 26.17854118347168\n",
      "epoch: 3200, train_loss: 32.3253288269043, test_loss: 24.889324188232422\n",
      "epoch: 3300, train_loss: 31.148544311523438, test_loss: 23.775405883789062\n",
      "epoch: 3400, train_loss: 30.132980346679688, test_loss: 22.801074981689453\n",
      "epoch: 3500, train_loss: 29.243127822875977, test_loss: 21.930219650268555\n",
      "epoch: 3600, train_loss: 28.441650390625, test_loss: 21.135690689086914\n",
      "epoch: 3700, train_loss: 27.705188751220703, test_loss: 20.40117645263672\n",
      "epoch: 3800, train_loss: 27.015003204345703, test_loss: 19.7085018157959\n",
      "epoch: 3900, train_loss: 26.35927963256836, test_loss: 19.05607795715332\n",
      "epoch: 4000, train_loss: 25.73211669921875, test_loss: 18.432025909423828\n",
      "epoch: 4100, train_loss: 25.12329864501953, test_loss: 17.835668563842773\n",
      "epoch: 4200, train_loss: 24.529083251953125, test_loss: 17.261621475219727\n",
      "epoch: 4300, train_loss: 23.945993423461914, test_loss: 16.706974029541016\n",
      "epoch: 4400, train_loss: 23.37371826171875, test_loss: 16.167940139770508\n",
      "epoch: 4500, train_loss: 22.808013916015625, test_loss: 15.64072036743164\n",
      "epoch: 4600, train_loss: 22.24654769897461, test_loss: 15.13598918914795\n",
      "epoch: 4700, train_loss: 21.690723419189453, test_loss: 14.650749206542969\n",
      "epoch: 4800, train_loss: 21.14443016052246, test_loss: 14.178515434265137\n",
      "epoch: 4900, train_loss: 20.605676651000977, test_loss: 13.7229585647583\n",
      "epoch: 5000, train_loss: 20.07230567932129, test_loss: 13.281689643859863\n",
      "epoch: 5100, train_loss: 19.543445587158203, test_loss: 12.839574813842773\n",
      "epoch: 5200, train_loss: 19.025854110717773, test_loss: 12.416571617126465\n",
      "epoch: 5300, train_loss: 18.51947021484375, test_loss: 12.002007484436035\n",
      "epoch: 5400, train_loss: 18.022666931152344, test_loss: 11.602546691894531\n",
      "epoch: 5500, train_loss: 17.538166046142578, test_loss: 11.224409103393555\n",
      "epoch: 5600, train_loss: 17.070087432861328, test_loss: 10.869659423828125\n",
      "epoch: 5700, train_loss: 16.617090225219727, test_loss: 10.53777027130127\n",
      "epoch: 5800, train_loss: 16.17730712890625, test_loss: 10.221857070922852\n",
      "epoch: 5900, train_loss: 15.753400802612305, test_loss: 9.935654640197754\n",
      "epoch: 6000, train_loss: 15.348119735717773, test_loss: 9.67092514038086\n",
      "epoch: 6100, train_loss: 14.956475257873535, test_loss: 9.420504570007324\n",
      "epoch: 6200, train_loss: 14.581716537475586, test_loss: 9.175822257995605\n",
      "epoch: 6300, train_loss: 14.223210334777832, test_loss: 8.95962142944336\n",
      "epoch: 6400, train_loss: 13.886449813842773, test_loss: 8.7620210647583\n",
      "epoch: 6500, train_loss: 13.569232940673828, test_loss: 8.581068992614746\n",
      "epoch: 6600, train_loss: 13.270463943481445, test_loss: 8.424042701721191\n",
      "epoch: 6700, train_loss: 12.988210678100586, test_loss: 8.288670539855957\n",
      "epoch: 6800, train_loss: 12.72071647644043, test_loss: 8.17685604095459\n",
      "epoch: 6900, train_loss: 12.46625804901123, test_loss: 8.082596778869629\n",
      "epoch: 7000, train_loss: 12.223885536193848, test_loss: 8.000852584838867\n",
      "epoch: 7100, train_loss: 11.997039794921875, test_loss: 7.9324631690979\n",
      "epoch: 7200, train_loss: 11.778687477111816, test_loss: 7.883808612823486\n",
      "epoch: 7300, train_loss: 11.572710990905762, test_loss: 7.834046840667725\n",
      "epoch: 7400, train_loss: 11.37592601776123, test_loss: 7.789514064788818\n",
      "epoch: 7500, train_loss: 11.190454483032227, test_loss: 7.758039474487305\n",
      "epoch: 7600, train_loss: 11.012866973876953, test_loss: 7.738765239715576\n",
      "epoch: 7700, train_loss: 10.843475341796875, test_loss: 7.715217590332031\n",
      "epoch: 7800, train_loss: 10.68049144744873, test_loss: 7.697423934936523\n",
      "epoch: 7900, train_loss: 10.52364730834961, test_loss: 7.684098243713379\n",
      "epoch: 8000, train_loss: 10.373344421386719, test_loss: 7.663000106811523\n",
      "epoch: 8100, train_loss: 10.224249839782715, test_loss: 7.649544715881348\n",
      "epoch: 8200, train_loss: 10.079964637756348, test_loss: 7.640950679779053\n",
      "程序结束时的测试数据的最小loss:7.640710830688477,当前模型测试数据的loss:7.640713691711426\n"
     ]
    }
   ],
   "source": [
    "epochs = 20000\n",
    "test_min_loss = 1000000\n",
    "train_loss_epoch = []\n",
    "all_train_loss = [] #训练集的损失\n",
    "all_test_loss = [] #测试集的损失\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for i,data in enumerate(dataloader):\n",
    "        #每次取一个batch的数据\n",
    "        \n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "        \n",
    "        #前向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        #计算loss\n",
    "\n",
    "        loss = criterion(outputs, labels.view(-1,1))\n",
    "        train_loss_epoch.append(loss.item())\n",
    "    all_train_loss.append(np.mean(train_loss_epoch))\n",
    "\n",
    "    train_loss_epoch = []\n",
    "    #测试集合\n",
    "    pred = model.forward(x_test)\n",
    "    test_loss = criterion(pred, y_test.view(-1,1))\n",
    "    all_test_loss.append(test_loss.item())\n",
    "\n",
    "    if test_min_loss > test_loss.item():\n",
    "        test_min_loss = test_loss.item()\n",
    "    else:\n",
    "        print(f'程序结束时的测试数据的最小loss:{test_min_loss},当前模型测试数据的loss:{test_loss.item()}')\n",
    "        break\n",
    "    if epoch % 100 == 0:\n",
    "        \n",
    "#             print('epoch {}, train_loss {},test_loss {}'.format(epoch, loss.item(),loss_test.item()))\n",
    "        print(f'epoch: {epoch}, train_loss: {loss.item()}, test_loss: {test_loss.item()}')\n",
    "    #梯度清零\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    #反向传播\n",
    "    loss.backward()\n",
    "\n",
    "    #更新参数\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19.1190]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "19.9\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.tensor(X_test[5],dtype=torch.float32).view(1,-1)\n",
    "print(model(input_.to(device)))\n",
    "print(Y_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.tensor(X_test,dtype=torch.float32)\n",
    "predicts = model(input_.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913109480680748"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(predicts.detach().cpu().numpy(),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19a489a1a88>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(len(all_train_loss[2000:])), all_train_loss[2000:], color='red',label='train_loss')\n",
    "plt.plot(np.arange(len(all_test_loss[2000:])), all_test_loss[2000:], color='blue',label='test_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值：44.171424865722656,真实值：43.8\n"
     ]
    }
   ],
   "source": [
    "#加载模型\n",
    "net = torch.load(\"model/model.pkl\")\n",
    "\n",
    "x_data = torch.tensor(X_test[1], dtype=torch.float32)\n",
    "\n",
    "pred = net.forward(x_data.view(1,-1).to(device))\n",
    "\n",
    "print('预测值：{},真实值：{}'.format(pred.item(),Y_test[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
